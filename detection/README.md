# CNN for detection
Training is performed via Darkflow library. For detection there are two approaches presented:
via Darkflow and via pure TensorFlow.
___

## Training the detector
According to the guide on the [official website](https://pjreddie.com/darknet/yolo/)
it's required to prepare dataset in the following way:
 * Images folder of each part of dataset, and corresponding labels folder
  should be inside one directory. Each label file should have the name of corresponding image file but 
 with ".txt" extension.  
 └── dataset  
 &nbsp;&nbsp;&nbsp;&nbsp;├── part1  
 &nbsp;&nbsp;&nbsp;&nbsp;│   ├── images  
 &nbsp;&nbsp;&nbsp;&nbsp;│   │   └── img0001.jpg  
 &nbsp;&nbsp;&nbsp;&nbsp;│   └── labels  
 &nbsp;&nbsp;&nbsp;&nbsp;│    &nbsp;&nbsp;&nbsp;&nbsp; └── img0001.txt  
 &nbsp;&nbsp;&nbsp;&nbsp;└── part2  
 &nbsp;&nbsp;&nbsp;&nbsp; . . .
 
 * In the label file there should be a line for each labeled object in the
 format:  
 `<object-class> <x> <y> <width> <height>`  
 where `<object-class>` is the serial number of the class among considered
 classes, `<x> <y>` are coordinates of top left corner of the bounding box, 
 `<width> <height>` are sizes of the bounding box. The latter four should be
 presented relatively to image sizes (in interval `[0; 1]`).
 
 To establish training pipeline via Darkflow we selected Caltech dataset
 (as it is easy to add data from KAIST dataset so together they will 
 combine really huge dataset) and wrote a script `data-eval/caltech2yolo.py`
 to  prepare it according to Darknet format for pedestrian 
 ("person" label) detection. It is also required to apply patch 
 `Train_on_Caltech.patch` from the root folder of the repository before
 installing Darkflow. This process is described in `dev-env.md`.
 
 Also some changes in configuration are required. In Darkflow directory
 file `labels.txt` should contain only one word: `person`. And you have to 
 copy in you`darkflow/cfg` folder network configuration file `tiny-yolo-pedect.cfg`
 from the root of this repository. 
 
 After all preparations you could train a new model with command 
 (from Darkflow directory):  
 `flow --model cfg/tiny-yolo-pedect.cfg --train --annotation "/home/rr/Desktop/Caltech_ped_det/part/labels/" --dataset "/home/rr/Desktop/Caltech_ped_det/part/frames/"`
 
 Darkflow also allows to perform transfer learning, so you could use
 weights of already trained network. For this you could download
 weights from Darknet website and put them in your `darkflow/bin` 
 folder. Darkflow will automatically define what layers are the same
 comparing with configuration file with the same name as weights file.
 For example for our problem one could do like this:  
 `flow --model cfg/tiny-yolo-pedect.cfg --load bin/tiny-yolo-voc.weights --train --annotation "/home/rr/Desktop/Caltech_ped_det/part/labels/" --dataset "/home/rr/Desktop/Caltech_ped_det/part/frames/"`
 
 For further use outside the Darkflow framework it's possible to save
 the whole TensorFlow model as protobuf file, also YOLO requires meta
 parameters to perform postprocessing, so Darkflow will create 2 files
 via the command of the following format:  
 `flow --model cfg/tiny-yolo-pedect.cfg --load bin/tiny-yolo-voc.weights --savepb`  
 The result would be:
 ```
 build-graph
    ├── tiny-yolo-pedect.meta
    └── tiny-yolo-pedect.pb
 ```
 ___
 
 
## Inference via Darkflow
Running existing detectors is pretty straight forward. One could follow
instructions in Darkflow repository. 

To provide examples we wrote 
scripts: `detection/cam_inferance.py` and `detection/img_inference.py`.  
To run them one should download from Darknet website [weights](https://pjreddie.com/media/files/tiny-yolo-voc.weights`) 
of TinyYOLO network trained on PASCAL VOC dataset.
___

## Inference via "objdet" package (almost pure TensorFlow)
As Darkflow is written in Python3 we experinced a lot of problems trying 
to use it as is in ROS. So the only solution was to create pure TenserFlow 
implementation for Python2. For this we had to adapt for Python2 some original
Darkflow code to be able to perform detection. The result is "objdet"
package, which is much lighter and less complex than Darkflow. 
It allows to perform detection using protobuf and meta files
generated by Darkflow.

To install "objdet" package run following commands:
```
$ cd detection
$ pip install .
```

To use "objdet" detection package in another script one just have to import 
"Detector" class from "objdet", initialize it's instance using 
protobuf and meta files, and perform detection for image as 
numpy array selecting threshold for confidence level of detection.

```
from objdet.pure_tf_detector import Detector

detector = Detector(pb_file_path, meta_file_path)

bounding_boxes = detector.return_predict(img, threshold)
```

The result would be list of bounding boxes presented as 
Python dictionary of the following format:  
`{'bottomright': {'x': 264, 'y': 213}, 'confidence': 0.3534133, 'label': 'car', 'topleft': {'x': 193, 'y': 174}}`

There is example script `pure_tf_cam.py` which performs detection for
camera stream using "objdet" package. To run it one could use 
required files from `detection/build_graph` folder.
